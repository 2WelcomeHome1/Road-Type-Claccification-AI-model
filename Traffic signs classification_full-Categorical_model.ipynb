{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c923be10",
   "metadata": {
    "id": "c923be10"
   },
   "source": [
    "# Классификация знаков Дорожного Движения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19abae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4643705",
   "metadata": {
    "id": "e4643705"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.10.0\n",
      "GPU is ON\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from skimage import transform\n",
    "\n",
    "print(f'Tensorflow version {tf.__version__}')\n",
    "print(f'GPU is {\"ON\" if tf.compat.v1.config.experimental.list_physical_devices(\"GPU\") else \"OFF\" }')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib, random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from imutils import paths\n",
    "import os\n",
    "import pathlib\n",
    "import LRFinder\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57469cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_signs_classes = {'0':183,\n",
    "                     '1':184,\n",
    "                     '2':185,\n",
    "                     '3':186,\n",
    "                     '4':187,\n",
    "                     '5':188,\n",
    "                     '6':189,\n",
    "                     '7':190,\n",
    "                     '8':191,\n",
    "                     '9':192,\n",
    "                     '10':193,\n",
    "                     '11':194,\n",
    "                     '12':195,\n",
    "                     '13':196,\n",
    "                     '14':197,\n",
    "                     '15':198,\n",
    "                     '16':199,\n",
    "                     '17':200,\n",
    "                     '18':201,\n",
    "                     '19':202,\n",
    "                     '20':203,\n",
    "                     '21':204}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d49e8621",
   "metadata": {},
   "outputs": [],
   "source": [
    "forb_signs_classes = {'0':0,\n",
    "'1':1,\n",
    "'2':10,\n",
    "'3':15,\n",
    "'4':16,\n",
    "'5':17,\n",
    "'6':2,\n",
    "'7':3,\n",
    "'8':32,\n",
    "'9':4,\n",
    "'10':41,\n",
    "'11':42,\n",
    "'12':5,\n",
    "'13':6,\n",
    "'14':7,\n",
    "'15':72,\n",
    "'16':73,\n",
    "'17':74,\n",
    "'18':75,\n",
    "'19':76,\n",
    "'20':77,\n",
    "'21':78,\n",
    "'22':79,\n",
    "'23':8,\n",
    "'24':80,\n",
    "'25':81,\n",
    "'26':82,\n",
    "'27':83,\n",
    "'28':84,\n",
    "'29':85,\n",
    "'30':86,\n",
    "'31':87,\n",
    "'32':88,\n",
    "'33':89,\n",
    "'34':9,\n",
    "'35':90,\n",
    "'36':91,\n",
    "'37':92,\n",
    "'38':93,\n",
    "'39':94,\n",
    "'40':95,\n",
    "'41':96,\n",
    "'42':97,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47bd1fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Warning_signs_classes = {'0':18,\n",
    "'1':19,\n",
    "'2':20,\n",
    "'3':21,\n",
    "'4':22,\n",
    "'5':23,\n",
    "'6':24,\n",
    "'7':25,\n",
    "'8':26,\n",
    "'9':27,\n",
    "'10':28,\n",
    "'11':29,\n",
    "'12':30,\n",
    "'13':31,\n",
    "'14':48,\n",
    "'15':49,\n",
    "'16':50,\n",
    "'17':51,\n",
    "'18':52,\n",
    "'19':53,\n",
    "'20':54,\n",
    "'21':55,\n",
    "'22':56,\n",
    "'23':57,\n",
    "'24':58,\n",
    "'25':59,\n",
    "'26':60,\n",
    "'27':61,\n",
    "'28':62,\n",
    "'29':63,\n",
    "'30':64,\n",
    "'31':65,\n",
    "'32':66,\n",
    "'33':67,\n",
    "'34':68,\n",
    "'35':69,\n",
    "'36':70,\n",
    "'37':71,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bab9fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_signs_classes = {'0':148,\n",
    "'1':149,\n",
    "'2':150,\n",
    "'3':151,\n",
    "'4':152,\n",
    "'5':153,\n",
    "'6':154,\n",
    "'7':155,\n",
    "'8':156,\n",
    "'9':157,\n",
    "'10':158,\n",
    "'11':159,\n",
    "'12':160,\n",
    "'13':161,\n",
    "'14':162,\n",
    "'15':163,\n",
    "'16':164,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49142321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = str(\"./New_Dataset/information_signs/\")\n",
    "# i = 0\n",
    "# for file_number in os.listdir(path):\n",
    "#     print(\"'\"+str(i)+\"'\"+\":\"+file_number+',')\n",
    "#     i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5a01586",
   "metadata": {},
   "outputs": [],
   "source": [
    "presc_signs_classes = {'0':100,\n",
    "'1':101,\n",
    "'2':102,\n",
    "'3':103,\n",
    "'4':104,\n",
    "'5':105,\n",
    "'6':106,\n",
    "'7':107,\n",
    "'8':108,\n",
    "'9':109,\n",
    "'10':33,\n",
    "'11':34,\n",
    "'12':35,\n",
    "'13':36,\n",
    "'14':37,\n",
    "'15':38,\n",
    "'16':39,\n",
    "'17':40,\n",
    "'18':98,\n",
    "'19':99,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "110b9d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "priority_signs_classes = {'0':12,\n",
    "'1':13,\n",
    "'2':14,\n",
    "'3':43,\n",
    "'4':44,\n",
    "'5':45,\n",
    "'6':46,\n",
    "'7':47,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aed927a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_signs_classes = {'0':165,\n",
    "'1':166,\n",
    "'2':167,\n",
    "'3':168,\n",
    "'4':169,\n",
    "'5':170,\n",
    "'6':171,\n",
    "'7':172,\n",
    "'8':173,\n",
    "'9':174,\n",
    "'10':175,\n",
    "'11':176,\n",
    "'12':177,\n",
    "'13':178,\n",
    "'14':179,\n",
    "'15':180,\n",
    "'16':181,\n",
    "'17':182,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb1773e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_instructions_signs_classes = {'0':110,\n",
    "'1':111,\n",
    "'2':112,\n",
    "'3':113,\n",
    "'4':114,\n",
    "'5':115,\n",
    "'6':116,\n",
    "'7':117,\n",
    "'8':118,\n",
    "'9':119,\n",
    "'10':120,\n",
    "'11':121,\n",
    "'12':122,\n",
    "'13':123,\n",
    "'14':124,\n",
    "'15':125,\n",
    "'16':126,\n",
    "'17':127,\n",
    "'18':128,\n",
    "'19':129,\n",
    "'20':130,\n",
    "'21':131,\n",
    "'22':132,\n",
    "'23':133,\n",
    "'24':134,\n",
    "'25':135,\n",
    "'26':136,\n",
    "'27':137,\n",
    "'28':138,\n",
    "'29':139,\n",
    "'30':140,\n",
    "'31':141,\n",
    "'32':142,\n",
    "'33':143,\n",
    "'34':144,\n",
    "'35':145,\n",
    "'36':146,\n",
    "'37':147,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e7cce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# categorical model\n",
    "categorical_model = models.load_model('./saved_models/Trafic_Signs_CNN_categorical.h5')\n",
    "\n",
    "# Signs model\n",
    "add_signs_model = models.load_model('./saved_models/Trafic_Signs_CNN_add_signs.h5')\n",
    "forb_signs_model = models.load_model('./saved_models/Trafic_Signs_CNN_forb_signs.h5')\n",
    "inf_signs_model = models.load_model('./saved_models/Trafic_Signs_CNN_inf_signs.h5')\n",
    "presc_signs_model = models.load_model('./saved_models/Trafic_Signs_CNN_presc_signs.h5')\n",
    "priority_signs_model = models.load_model('./saved_models/Trafic_Signs_CNN_priority_signs.h5')\n",
    "service_signs_model = models.load_model('./saved_models/Trafic_Signs_CNN_service_signs.h5')\n",
    "special_instructions_signs_model = models.load_model('./saved_models/Trafic_Signs_CNN_special_instructions_signs.h5')\n",
    "Warning_signs_model = models.load_model('./saved_models/Trafic_Signs_CNN_Warning_signs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bd601ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 58, 58, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 29, 29, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 29, 29, 32)        0         \n",
      "                                                                 \n",
      " zero_padding2d (ZeroPadding  (None, 31, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 6, 6, 128)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 2, 2, 256)         819456    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 1, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 1, 256)         0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1, 1, 256)        1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 957,224\n",
      "Trainable params: 956,712\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "categorical_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "132a94c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m img_batch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(image_resized,\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Начинаем предсказание категории знака\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m categorical_prediction \u001b[38;5;241m=\u001b[39m \u001b[43mcategorical_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m categorical_prediction \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(categorical_prediction, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     49\u001b[0m count \u001b[38;5;241m=\u001b[39m count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2253\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   2252\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 2253\u001b[0m     tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   2255\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:986\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    982\u001b[0m   _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    983\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    984\u001b[0m           \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m    985\u001b[0m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[1;32m--> 986\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_with_cond\u001b[39m(inner_args, inner_kwds, inner_filtered_flat_args):\n\u001b[0;32m    990\u001b[0m   \u001b[38;5;124;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./Data_images/Test_data.csv')\n",
    "ver=0\n",
    "count=0\n",
    "\n",
    "ver0=0\n",
    "count0=0\n",
    "\n",
    "ver1=0\n",
    "count1=0\n",
    "\n",
    "ver2=0\n",
    "count2=0\n",
    "\n",
    "ver3=0\n",
    "count3=0\n",
    "\n",
    "ver4=0\n",
    "count4=0\n",
    "\n",
    "ver5=0\n",
    "count5=0\n",
    "\n",
    "ver6=0\n",
    "count6=0\n",
    "\n",
    "ver7=0\n",
    "count7=0\n",
    "all_classes = []\n",
    "predicted_classes = []\n",
    "\n",
    "num_classes = 205\n",
    "for c in range (11):\n",
    "    for i in range(len(df.loc[df['ClassId'] == c])):\n",
    "        \n",
    "        all_classes.append(c)\n",
    "        # Считываем тестовый датасет\n",
    "        image_path = df.loc[df['ClassId'] == c].values[i][1]\n",
    "        classid = df.loc[df['ClassId'] == c].values[i][0]\n",
    "        \n",
    "        # Обрабатываем изображения\n",
    "        image = cv2.imread(str('./Data_images/' + str(image_path)), 1) ## Считываем изображение\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB) ## переводим в оттенки серого\n",
    "        image_resized = transform.resize(image, (60,60))\n",
    "        img_batch = np.expand_dims(image_resized,0)\n",
    "        \n",
    "        # Начинаем предсказание категории знака\n",
    "        categorical_prediction = categorical_model.predict(img_batch)\n",
    "        categorical_prediction = np.argmax(categorical_prediction, axis=1)\n",
    "        count = count+1\n",
    "        print(categorical_prediction[0])\n",
    "         # Начинаем предсказание знака внутри категории\n",
    "        if categorical_prediction[0] == 2:\n",
    "            \n",
    "            count2=count2+1\n",
    "            image_resized = transform.resize(image, (60,90))\n",
    "            img_batch = np.expand_dims(image_resized,0)\n",
    "            \n",
    "            add_signs_prediction = add_signs_model.predict(img_batch)\n",
    "            add_signs_prediction = np.argmax(add_signs_prediction, axis=1)\n",
    "            \n",
    "            predicted_classes.append(add_signs_classes[str(add_signs_prediction[0])])\n",
    "\n",
    "            if classid != add_signs_classes[str(add_signs_prediction[0])]:\n",
    "                ver = ver+1\n",
    "                ver2 = ver2+1\n",
    "                print(classid, add_signs_classes[(str(add_signs_prediction[0]))], add_signs_prediction[0], image_path)\n",
    "            \n",
    "        if categorical_prediction[0] == 0:\n",
    "            count0=count0+1\n",
    "#             image_resized = transform.resize(image, (60,60))\n",
    "#             img_batch = np.expand_dims(image_resized,0)\n",
    "            \n",
    "            forb_signs_prediction = forb_signs_model.predict(img_batch)\n",
    "            forb_signs_prediction = np.argmax(forb_signs_prediction, axis=1)\n",
    "            \n",
    "            predicted_classes.append(forb_signs_classes[(str(forb_signs_prediction[0]))])\n",
    "            \n",
    "            if classid != forb_signs_classes[(str(forb_signs_prediction[0]))]:\n",
    "                ver = ver+1\n",
    "                ver0=ver0+1\n",
    "                print(classid, forb_signs_classes[(str(forb_signs_prediction[0]))], forb_signs_prediction[0], image_path)\n",
    "                \n",
    "        if categorical_prediction[0] == 3:\n",
    "            count3=count3+1\n",
    "#             image_resized = transform.resize(image, (60,60))\n",
    "#             img_batch = np.expand_dims(image_resized,0)\n",
    "            \n",
    "            inf_signs_prediction = inf_signs_model.predict(img_batch)\n",
    "            inf_signs_prediction = np.argmax(inf_signs_prediction, axis=1)\n",
    "            \n",
    "            predicted_classes.append(inf_signs_classes[(str(inf_signs_prediction[0]))])\n",
    "            \n",
    "            if classid != inf_signs_classes[(str(inf_signs_prediction[0]))]:\n",
    "                ver = ver+1\n",
    "                ver3= ver3+1\n",
    "                print(classid, inf_signs_classes[(str(inf_signs_prediction[0]))], inf_signs_prediction[0], image_path)\n",
    "                 \n",
    "        if categorical_prediction[0] == 4:\n",
    "            count4=count4+1\n",
    "#             image_resized = transform.resize(image, (60,60))\n",
    "#             img_batch = np.expand_dims(image_resized,0)\n",
    "            \n",
    "            presc_signs_prediction = presc_signs_model.predict(img_batch)\n",
    "            presc_signs_prediction = np.argmax(presc_signs_prediction, axis=1)\n",
    "            \n",
    "            predicted_classes.append(presc_signs_classes[(str(presc_signs_prediction[0]))])\n",
    "            \n",
    "            if classid != presc_signs_classes[(str(presc_signs_prediction[0]))]:\n",
    "                ver = ver+1\n",
    "                ver4= ver4+1\n",
    "                print(classid, presc_signs_classes[(str(presc_signs_prediction[0]))], presc_signs_prediction[0], image_path)\n",
    "                 \n",
    "        if categorical_prediction[0] == 5:\n",
    "            count5=count5+1\n",
    "            image_resized = transform.resize(image, (70,70))\n",
    "            img_batch = np.expand_dims(image_resized,0)\n",
    "            \n",
    "            priority_signs_prediction = priority_signs_model.predict(img_batch)\n",
    "            priority_signs_prediction = np.argmax(priority_signs_prediction, axis=1)\n",
    "            \n",
    "            predicted_classes.append(priority_signs_classes[(str(priority_signs_prediction[0]))])\n",
    "            \n",
    "            if classid != priority_signs_classes[(str(priority_signs_prediction[0]))]:\n",
    "                ver = ver+1\n",
    "                ver5= ver5+1\n",
    "                print(classid, priority_signs_classes[(str(priority_signs_prediction[0]))], priority_signs_prediction[0], image_path)\n",
    "                \n",
    "        if categorical_prediction[0] == 6:\n",
    "            count6=count6+1\n",
    "            image_resized = transform.resize(image, (120,80))\n",
    "            img_batch = np.expand_dims(image_resized,0)\n",
    "            \n",
    "            service_sign_prediction = service_signs_model.predict(img_batch)\n",
    "            service_sign_prediction = np.argmax(service_sign_prediction, axis=1)\n",
    "            \n",
    "            predicted_classes.append(service_signs_classes[(str(service_sign_prediction[0]))])\n",
    "            \n",
    "            if classid != service_signs_classes[(str(service_sign_prediction[0]))]:\n",
    "                ver = ver+1\n",
    "                ver6= ver6+1\n",
    "                print(classid, service_signs_classes[(str(service_sign_prediction[0]))], service_sign_prediction[0], image_path)        \n",
    "                              \n",
    "        if categorical_prediction[0] == 7:\n",
    "            count7=count7+1\n",
    "#             image_resized = transform.resize(image, (60,60))\n",
    "#             img_batch = np.expand_dims(image_resized,0)\n",
    "            \n",
    "            special_instructions_signs_prediction = special_instructions_signs_model.predict(img_batch)\n",
    "            special_instructions_signs_prediction = np.argmax(special_instructions_signs_prediction, axis=1)\n",
    "            \n",
    "            predicted_classes.append(special_instructions_signs_classes[(str(special_instructions_signs_prediction[0]))])\n",
    "            \n",
    "            if classid != special_instructions_signs_classes[(str(special_instructions_signs_prediction[0]))]:\n",
    "                ver = ver+1\n",
    "                ver7= ver7+1\n",
    "                print(classid, special_instructions_signs_classes[(str(special_instructions_signs_prediction[0]))], special_instructions_signs_prediction[0], image_path)\n",
    "                \n",
    "        if categorical_prediction[0] == 1:\n",
    "            count1=count1+1\n",
    "\n",
    "#             image_resized = transform.resize(image, (60,60))\n",
    "#             img_batch = np.expand_dims(image_resized,0)\n",
    "            \n",
    "            Warning_signs_prediction = Warning_signs_model.predict(img_batch)\n",
    "            Warning_signs_prediction = np.argmax(Warning_signs_prediction, axis=1)\n",
    "            \n",
    "            predicted_classes.append(Warning_signs_classes[(str(Warning_signs_prediction[0]))])\n",
    "            \n",
    "            if classid != Warning_signs_classes[(str(Warning_signs_prediction[0]))]:\n",
    "                ver = ver+1\n",
    "                ver1 = ver1+1\n",
    "                print(classid,Warning_signs_classes[(str(Warning_signs_prediction[0]))], Warning_signs_prediction[0], image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581d3f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range (12, num_classes):\n",
    "    for i in range(len(df.loc[df['ClassId'] == c])):\n",
    "        \n",
    "        all_classes.append(c)\n",
    "        # Считываем тестовый датасет\n",
    "        image_path = df.loc[df['ClassId'] == c].values[i][1]\n",
    "        classid = df.loc[df['ClassId'] == c].values[i][0]\n",
    "        \n",
    "        # Обрабатываем изображения\n",
    "        image = cv2.imread(str('./Data_images/' + str(image_path)), 1) ## Считываем изображение\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB) ## переводим в оттенки серого\n",
    "        image_resized = transform.resize(image, (60,60))\n",
    "        img_batch = np.expand_dims(image_resized,0)\n",
    "        \n",
    "        # Начинаем предсказание категории знака\n",
    "        categorical_prediction = categorical_model.predict(img_batch)\n",
    "        categorical_prediction = np.argmax(categorical_prediction, axis=1)\n",
    "        count = count+1\n",
    "        print(categorical_prediction[0])\n",
    "         # Начинаем предсказание знака внутри категории\n",
    "        if categorical_prediction[0] == 2:\n",
    "            \n",
    "            count2=count2+1\n",
    "            image_resized = transform.resize(image, (60,90))\n",
    "            img_batch = np.expand_dims(image_resized,0)\n",
    "            \n",
    "            add_signs_prediction = add_signs_model.predict(img_batch)\n",
    "            add_signs_prediction = np.argmax(add_signs_prediction, axis=1)\n",
    "            \n",
    "            predicted_classes.append(add_signs_classes[str(add_signs_prediction[0])])\n",
    "\n",
    "            if classid != add_signs_classes[str(add_signs_prediction[0])]:\n",
    "                ver = ver+1\n",
    "                ver2 = ver2+1\n",
    "                print(classid, add_signs_classes[(str(add_signs_prediction[0]))], add_signs_prediction[0], image_path)\n",
    "            \n",
    "        if categorical_prediction[0] == 0:\n",
    "            count0=count0+1\n",
    "#             image_resized = transform.resize(image, (60,60))\n",
    "#             img_batch = np.expand_dims(image_resized,0)\n",
    "            \n",
    "            forb_signs_prediction = forb_signs_model.predict(img_batch)\n",
    "            forb_signs_prediction = np.argmax(forb_signs_prediction, axis=1)\n",
    "            \n",
    "            predicted_classes.append(forb_signs_classes[(str(forb_signs_prediction[0]))])\n",
    "            \n",
    "            if classid != forb_signs_classes[(str(forb_signs_prediction[0]))]:\n",
    "                ver = ver+1\n",
    "                ver0=ver0+1\n",
    "                print(classid, forb_signs_classes[(str(forb_signs_prediction[0]))], forb_signs_prediction[0], image_path)\n",
    "                \n",
    "        if categorical_prediction[0] == 3:\n",
    "            count3=count3+1\n",
    "#             image_resized = transform.resize(image, (60,60))\n",
    "#             img_batch = np.expand_dims(image_resized,0)\n",
    "            \n",
    "            inf_signs_prediction = inf_signs_model.predict(img_batch)\n",
    "            inf_signs_prediction = np.argmax(inf_signs_prediction, axis=1)\n",
    "            \n",
    "            predicted_classes.append(inf_signs_classes[(str(inf_signs_prediction[0]))])\n",
    "            \n",
    "            if classid != inf_signs_classes[(str(inf_signs_prediction[0]))]:\n",
    "                ver = ver+1\n",
    "                ver3= ver3+1\n",
    "                print(classid, inf_signs_classes[(str(inf_signs_prediction[0]))], inf_signs_prediction[0], image_path)\n",
    "                 \n",
    "        if categorical_prediction[0] == 4:\n",
    "            count4=count4+1\n",
    "#             image_resized = transform.resize(image, (60,60))\n",
    "#             img_batch = np.expand_dims(image_resized,0)\n",
    "            \n",
    "            presc_signs_prediction = presc_signs_model.predict(img_batch)\n",
    "            presc_signs_prediction = np.argmax(presc_signs_prediction, axis=1)\n",
    "            \n",
    "            predicted_classes.append(presc_signs_classes[(str(presc_signs_prediction[0]))])\n",
    "            \n",
    "            if classid != presc_signs_classes[(str(presc_signs_prediction[0]))]:\n",
    "                ver = ver+1\n",
    "                ver4= ver4+1\n",
    "                print(classid, presc_signs_classes[(str(presc_signs_prediction[0]))], presc_signs_prediction[0], image_path)\n",
    "                 \n",
    "        if categorical_prediction[0] == 5:\n",
    "            count5=count5+1\n",
    "            image_resized = transform.resize(image, (70,70))\n",
    "            img_batch = np.expand_dims(image_resized,0)\n",
    "            \n",
    "            priority_signs_prediction = priority_signs_model.predict(img_batch)\n",
    "            priority_signs_prediction = np.argmax(priority_signs_prediction, axis=1)\n",
    "            \n",
    "            predicted_classes.append(priority_signs_classes[(str(priority_signs_prediction[0]))])\n",
    "            \n",
    "            if classid != priority_signs_classes[(str(priority_signs_prediction[0]))]:\n",
    "                ver = ver+1\n",
    "                ver5= ver5+1\n",
    "                print(classid, priority_signs_classes[(str(priority_signs_prediction[0]))], priority_signs_prediction[0], image_path)\n",
    "                \n",
    "        if categorical_prediction[0] == 6:\n",
    "            count6=count6+1\n",
    "            image_resized = transform.resize(image, (120,80))\n",
    "            img_batch = np.expand_dims(image_resized,0)\n",
    "            \n",
    "            service_sign_prediction = service_signs_model.predict(img_batch)\n",
    "            service_sign_prediction = np.argmax(service_sign_prediction, axis=1)\n",
    "            \n",
    "            predicted_classes.append(service_signs_classes[(str(service_sign_prediction[0]))])\n",
    "            \n",
    "            if classid != service_signs_classes[(str(service_sign_prediction[0]))]:\n",
    "                ver = ver+1\n",
    "                ver6= ver6+1\n",
    "                print(classid, service_signs_classes[(str(service_sign_prediction[0]))], service_sign_prediction[0], image_path)        \n",
    "                              \n",
    "        if categorical_prediction[0] == 7:\n",
    "            count7=count7+1\n",
    "#             image_resized = transform.resize(image, (60,60))\n",
    "#             img_batch = np.expand_dims(image_resized,0)\n",
    "            \n",
    "            special_instructions_signs_prediction = special_instructions_signs_model.predict(img_batch)\n",
    "            special_instructions_signs_prediction = np.argmax(special_instructions_signs_prediction, axis=1)\n",
    "            \n",
    "            predicted_classes.append(special_instructions_signs_classes[(str(special_instructions_signs_prediction[0]))])\n",
    "            \n",
    "            if classid != special_instructions_signs_classes[(str(special_instructions_signs_prediction[0]))]:\n",
    "                ver = ver+1\n",
    "                ver7= ver7+1\n",
    "                print(classid, special_instructions_signs_classes[(str(special_instructions_signs_prediction[0]))], special_instructions_signs_prediction[0], image_path)\n",
    "                \n",
    "        if categorical_prediction[0] == 1:\n",
    "            count1=count1+1\n",
    "\n",
    "#             image_resized = transform.resize(image, (60,60))\n",
    "#             img_batch = np.expand_dims(image_resized,0)\n",
    "            \n",
    "            Warning_signs_prediction = Warning_signs_model.predict(img_batch)\n",
    "            Warning_signs_prediction = np.argmax(Warning_signs_prediction, axis=1)\n",
    "            \n",
    "            predicted_classes.append(Warning_signs_classes[(str(Warning_signs_prediction[0]))])\n",
    "            \n",
    "            if classid != Warning_signs_classes[(str(Warning_signs_prediction[0]))]:\n",
    "                ver = ver+1\n",
    "                ver1 = ver1+1\n",
    "                print(classid,Warning_signs_classes[(str(Warning_signs_prediction[0]))], Warning_signs_prediction[0], image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a91eb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "test_accuracy = ver/count\n",
    "print(ver,count ,round((1-test_accuracy)*100,2))\n",
    "print (f1_score(all_classes, predicted_classes, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa444dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df22b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
